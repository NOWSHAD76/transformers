{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerConfig,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.modeling_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerForConditionalGeneration,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import *\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "from loguru import logger\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig, AutoModel\n",
    "\n",
    "# from loguru import logger\n",
    "# from transformers import AutoConfig\n",
    "\n",
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerThinkerTextConfig,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.modeling_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerThinkerTextModel,\n",
    ")\n",
    "\n",
    "configs = {\n",
    "    # \"gemma3_thinker\": Gemma3ThinkerConfig,\n",
    "    # \"gemma3_talker\": Gemma3TalkerConfig,\n",
    "    # \"gemma3_token2wav\": Gemma3Token2WavConfig,\n",
    "    # \"gemma3_with_talker\": Gemma3WithTalkerConfig,\n",
    "    \"gemma3_with_talker_thinker_text\": Gemma3WithTalkerThinkerTextConfig,\n",
    "    # \"gemma3_bigvgan\": Gemma3BigVGANConfig,\n",
    "    # \"gemma3_dit\": Gemma3DiTConfig,\n",
    "}\n",
    "for name, conf in configs.items():\n",
    "    AutoConfig.register(name, conf)\n",
    "\n",
    "# AutoConfig.register(\"gemma3_with_talker\", Gemma3WithTalkerConfig)\n",
    "AutoModel.register(Gemma3WithTalkerThinkerTextConfig, Gemma3WithTalkerThinkerTextModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LIBRARY_PATH\"] = \"/usr/local/cuda/lib64/stubs:$LIBRARY_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-30 15:07:42.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4826\u001b[0m - \u001b[1mInside from pretrained\u001b[0m\n",
      "\u001b[32m2025-05-30 15:07:42.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4827\u001b[0m - \u001b[34m\u001b[1mConfig None\u001b[0m\n",
      "\u001b[32m2025-05-30 15:07:42.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4828\u001b[0m - \u001b[34m\u001b[1mModel args\u001b[0m\n",
      "\u001b[32m2025-05-30 15:07:42.166\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4830\u001b[0m - \u001b[34m\u001b[1mkwargs\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4982f8e9c24cd785c2191ff495e3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Linear:\n\tsize mismatch for weight: copying a param with shape torch.Size([152064, 3584]) from checkpoint, the shape in current model is torch.Size([262145, 3840]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGemma3WithTalkerForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data1/nowshad/models/gemma3_with_talker_base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"/data1/nowshad/models/gemma3_with_talker_merge\",\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# config=config,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbfloat16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ignore_mismatched_sizes=True,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/gemma3_with_talker/modeling_gemma3_with_talker.py:4832\u001b[0m, in \u001b[0;36mGemma3WithTalkerForConditionalGeneration.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4830\u001b[0m logger_v2\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4831\u001b[0m \u001b[38;5;66;03m# print(**kwargs)\u001b[39;00m\n\u001b[0;32m-> 4832\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4844\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4846\u001b[0m spk_path \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   4847\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   4848\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspk_dict.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4856\u001b[0m     revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   4857\u001b[0m )\n\u001b[1;32m   4858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spk_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:314\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:4688\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4679\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4681\u001b[0m     (\n\u001b[1;32m   4682\u001b[0m         model,\n\u001b[1;32m   4683\u001b[0m         missing_keys,\n\u001b[1;32m   4684\u001b[0m         unexpected_keys,\n\u001b[1;32m   4685\u001b[0m         mismatched_keys,\n\u001b[1;32m   4686\u001b[0m         offload_index,\n\u001b[1;32m   4687\u001b[0m         error_msgs,\n\u001b[0;32m-> 4688\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4694\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4697\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4706\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4707\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:5144\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5141\u001b[0m         args_list \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mtqdm(args_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint shards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[0;32m-> 5144\u001b[0m         _error_msgs, disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5145\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _error_msgs\n\u001b[1;32m   5147\u001b[0m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:935\u001b[0m, in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m--> 935\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:847\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled():\n\u001b[1;32m    845\u001b[0m         param_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 847\u001b[0m     \u001b[43m_load_parameter_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(\n\u001b[1;32m    851\u001b[0m         model, param, param_name, param_device, state_dict, unexpected_keys\n\u001b[1;32m    852\u001b[0m     )\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:735\u001b[0m, in \u001b[0;36m_load_parameter_into_model\u001b[0;34m(model, param_name, tensor)\u001b[0m\n\u001b[1;32m    733\u001b[0m module, param_type \u001b[38;5;241m=\u001b[39m get_module_from_name(model, param_name)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;66;03m# This will check potential shape mismatch if skipped before\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mparam_type\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Linear:\n\tsize mismatch for weight: copying a param with shape torch.Size([152064, 3584]) from checkpoint, the shape in current model is torch.Size([262145, 3840])."
     ]
    }
   ],
   "source": [
    "model = Gemma3WithTalkerForConditionalGeneration.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base\",\n",
    "    # \"/data1/nowshad/models/gemma3_with_talker_merge\",\n",
    "    device_map=\"cuda:6\",\n",
    "    # config=config,\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    # ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3WithTalkerForConditionalGeneration(\n",
       "  (thinker): Gemma3WithTalkerThinkerForConditionalGeneration(\n",
       "    (model): Gemma3WithTalkerThinkerModel(\n",
       "      (vision_tower): SiglipVisionModel(\n",
       "        (vision_model): SiglipVisionTransformer(\n",
       "          (embeddings): SiglipVisionEmbeddings(\n",
       "            (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "            (position_embedding): Embedding(4096, 1152)\n",
       "          )\n",
       "          (encoder): SiglipEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-26): 27 x SiglipEncoderLayer(\n",
       "                (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (self_attn): SiglipAttention(\n",
       "                  (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): SiglipMLP(\n",
       "                  (activation_fn): PytorchGELUTanh()\n",
       "                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (multi_modal_projector): Gemma3WithTalkerThinkerMultiModalProjector(\n",
       "        (mm_soft_emb_norm): Gemma3WithTalkerThinkerRMSNorm((1152,), eps=1e-06)\n",
       "        (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "      )\n",
       "      (language_model): Gemma3WithTalkerThinkerTextModel(\n",
       "        (embed_tokens): Gemma3WithTalkerThinkerTextScaledWordEmbedding(262145, 3840, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-47): 48 x Gemma3WithTalkerThinkerDecoderLayer(\n",
       "            (self_attn): Gemma3WithTalkerThinkerAttention(\n",
       "              (q_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
       "              (k_proj): Linear(in_features=3840, out_features=2048, bias=False)\n",
       "              (v_proj): Linear(in_features=3840, out_features=2048, bias=False)\n",
       "              (o_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
       "              (q_norm): Gemma3WithTalkerThinkerRMSNorm((256,), eps=1e-06)\n",
       "              (k_norm): Gemma3WithTalkerThinkerRMSNorm((256,), eps=1e-06)\n",
       "            )\n",
       "            (mlp): Gemma3WithTalkerThinkerMLP(\n",
       "              (gate_proj): Linear(in_features=3840, out_features=15360, bias=False)\n",
       "              (up_proj): Linear(in_features=3840, out_features=15360, bias=False)\n",
       "              (down_proj): Linear(in_features=15360, out_features=3840, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "        (rotary_emb): Gemma3WithTalkerThinkerRotaryEmbedding()\n",
       "        (rotary_emb_local): Gemma3WithTalkerThinkerRotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=3840, out_features=262145, bias=False)\n",
       "  )\n",
       "  (projection_thinker_L0): Linear(in_features=3840, out_features=3584, bias=True)\n",
       "  (projection_thinker_LN): Linear(in_features=3840, out_features=3584, bias=True)\n",
       "  (projection_thinker_vocab): Linear(in_features=3840, out_features=3584, bias=True)\n",
       "  (talker): Gemma3WithTalkerTalkerForConditionalGeneration(\n",
       "    (thinker_to_talker_proj): Linear(in_features=3584, out_features=896, bias=True)\n",
       "    (model): Gemma3WithTalkerTalkerModel(\n",
       "      (embed_tokens): Embedding(8448, 3584)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Gemma3WithTalkerTalkerDecoderLayer(\n",
       "          (self_attn): Gemma3WithTalkerSdpaAttention(\n",
       "            (q_proj): Linear(in_features=896, out_features=1536, bias=True)\n",
       "            (k_proj): Linear(in_features=896, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=896, out_features=512, bias=True)\n",
       "            (o_proj): Linear(in_features=1536, out_features=896, bias=False)\n",
       "            (rotary_emb): Gemma3WithTalkerRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=896, out_features=18944, bias=False)\n",
       "            (up_proj): Linear(in_features=896, out_features=18944, bias=False)\n",
       "            (down_proj): Linear(in_features=18944, out_features=896, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (rotary_emb): Gemma3WithTalkerRotaryEmbedding()\n",
       "    )\n",
       "    (codec_head): Linear(in_features=896, out_features=8448, bias=False)\n",
       "  )\n",
       "  (token2wav): Gemma3WithTalkerToken2WavModel(\n",
       "    (code2wav_dit_model): Gemma3WithTalkerToken2WavDiTModel(\n",
       "      (time_embed): DiTTimestepEmbedding(\n",
       "        (time_embed): SinusPositionEmbedding()\n",
       "        (time_mlp): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (text_embed): DiTCodecEmbedding(\n",
       "        (codec_embed): Embedding(8194, 512)\n",
       "      )\n",
       "      (input_embed): DiTInputEmbedding(\n",
       "        (proj): Linear(in_features=912, out_features=1024, bias=True)\n",
       "        (spk_encoder): ECAPA_TimeDelayNet(\n",
       "          (blocks): ModuleList(\n",
       "            (0): TimeDelayNetBlock(\n",
       "              (conv): Conv1d(80, 256, kernel_size=(5,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): SqueezeExcitationRes2NetBlock(\n",
       "              (tdnn1): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (res2net_block): Res2NetBlock(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): TimeDelayNetBlock(\n",
       "                    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,), padding_mode=reflect)\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (tdnn2): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (se_block): SqueezeExcitationBlock(\n",
       "                (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (conv2): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (2): SqueezeExcitationRes2NetBlock(\n",
       "              (tdnn1): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (res2net_block): Res2NetBlock(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): TimeDelayNetBlock(\n",
       "                    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, dilation=(3,), padding_mode=reflect)\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (tdnn2): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (se_block): SqueezeExcitationBlock(\n",
       "                (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (conv2): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (3): SqueezeExcitationRes2NetBlock(\n",
       "              (tdnn1): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (res2net_block): Res2NetBlock(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): TimeDelayNetBlock(\n",
       "                    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,), padding_mode=reflect)\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (tdnn2): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (se_block): SqueezeExcitationBlock(\n",
       "                (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (conv2): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (mfa): TimeDelayNetBlock(\n",
       "            (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (asp): AttentiveStatisticsPooling(\n",
       "            (tdnn): TimeDelayNetBlock(\n",
       "              (conv): Conv1d(2304, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (tanh): Tanh()\n",
       "            (conv): Conv1d(64, 768, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "          )\n",
       "          (fc): Conv1d(1536, 128, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "        )\n",
       "      )\n",
       "      (rotary_embed): Gemma3WithTalkerDiTRotaryEmbedding()\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0-21): 22 x DiTDecoderLayer(\n",
       "          (attn_norm): Gemma3WithTalkerAdaLayerNormZero(\n",
       "            (silu): SiLU()\n",
       "            (linear): Linear(in_features=1024, out_features=6144, bias=True)\n",
       "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)\n",
       "          )\n",
       "          (attn): DiTAttention(\n",
       "            (to_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (to_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (to_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (to_out): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)\n",
       "          (ff): DiTMLP(\n",
       "            (ff): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "              (1): GELU(approximate='tanh')\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): Gemma3WithTalkerAdaLayerNormZero_Final(\n",
       "        (silu): SiLU()\n",
       "        (linear): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1024, out_features=80, bias=True)\n",
       "    )\n",
       "    (code2wav_bigvgan_model): Gemma3WithTalkerToken2WavBigVGANModel(\n",
       "      (conv_pre): Conv1d(80, 1536, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ConvTranspose1d(1536, 768, kernel_size=(11,), stride=(5,), padding=(3,))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ConvTranspose1d(768, 384, kernel_size=(7,), stride=(3,), padding=(2,))\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ConvTranspose1d(384, 192, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): ConvTranspose1d(96, 48, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): ConvTranspose1d(48, 24, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (activation_post): TorchActivation1d(\n",
       "        (act): SnakeBeta()\n",
       "        (upsample): UpSample1d()\n",
       "        (downsample): DownSample1d()\n",
       "      )\n",
       "      (conv_post): Conv1d(24, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ea1f03de2c41ffb892812296c51e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForImageTextToText,\n",
    ")\n",
    "\n",
    "thinker_model = AutoModelForImageTextToText.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_12b_ft_20250519\",\n",
    "    # \"/data1/nowshad/models/Qwen2-7B\",\n",
    "    # \"/data1/nowshad/models/Qwen2.5-VL-7B-Instruct_processor\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    device_map=\"cuda:6\",\n",
    "    # trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.thinker = thinker_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "262208 - 262145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "thinker_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_12b_ft_20250519\"\n",
    ")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What is your name?\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "text = thinker_tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "# text = \"What is your name?\"\n",
    "inputs = thinker_tokenizer([text], return_tensors=\"pt\").to(\"cuda:6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "thinker_result = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids, audio = thinker_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user\\nYou are a helpful assistant.\\n\\nWhat is your name?\\nmodel\\nameni futuresfuturesfuturesfuturesfuturesCYCLONEDBnaleCYCLONEDBnale hnTTameenria convertido PA ria riaspeciestelefonet  ligeramentechore indicadochoreops Secure trouxe   indicado flera flera flera flera flera ops redwoodArrow  evamxbet forfeitedTT<unused3760> dialysisspeciespickerAware mi conjugationpicker masala ideales imme McClellan conjugationissezistar Nowhere responde FigurCYCLONEDBpicker LeBron reformingukiy frosteduning flera flera uningpicker arielpicker psor </pickerqueries aviation fjordpicker rd<unused6225> Louis PA ideales psor konse hennesRama Semantic TTalto McClellan psor fjord fjord fjord fjord fjord fjord fjord fjord fjord cornerRadius<unused1139>  ideales<unused1139>   ideales enea   jealous pread Hemen fallout  fallout estremamente   appel untoldlongrightarrowpread  falloutORDAN<unused6225><unused6091> pread QUAL equivariantently<unused6225> ISSUhlen sandalwood sandalwoodentlynaverISSUShirt<unused1139>ISSU ISSU differedISSU differedISSU differed rd rapedgaver<unused1139>ISSU untold Braga summertime inversion Hallo Braga inversion Bragapread inversionstica Braga summertime Braga sandalwood={[epamPilotBibitem Gonz daytimeBibitemBibitem decentralized VUequip Gonz giv  Bonnet givSCUS ideales konse konse differed remedial remedialdeterministic remedial remedial remedialBibitem remedialdeterministicdeterministicdeterministic  dorudeterministicdeterministic Teles BorderRadius estremamente remedial  Fuckarty  wisdom  VU  farther concours certe  hasta Encode  Span conjugation Ritzow conjugationow<unused5748> Ritz Ritz Ritz Ritz Ritzalmost Ritz Ritz Ritz Ritz Ritz Ritz Ritz Mandatory Dempsey VU hace diocese VU conjugationosten al conjugation conjugationissez conjugationissez certe haceBronzeelta Getrn neod([\\\\  BorderRadius untold remedial torna VU underside Mishra underside kpek Bibitem remedial underside underside underside termina battleship undersidevariables remedial remedial remedial underside underside undersideelta remedial underside underside undersidePropagation underside underside/\"> parlare remedial Bonnet underside underside conjugation remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial fallout remedial  remedial remedial remedial  remedial remedialZDZD iculares Encodeeltat conjugation Respssotherm ISSU<unused1139><unused1139> untold ISSUdienst  devils<unused1139> untold<unused1139> untoldnimo Encode untoldPrintedISSU chub WasnERVERISSU untoldISSU ghetto<unused1139> untold Butte Mandatory obdob untold   undersidevariables remedial remedial remedial remedial remedial remedial remedial remedial remedialently posto Section underside am Encode untoldISSU ghetto<unused5748><unused1139> untold untold Soo untold  Soo <unused2078> Encode untold differedarty  differedarty vormen  untold Span Encode untold playing  Encode Encode untold Soo Soo Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode psor kedua  Encode Encode Encode psor Encode Encode Encode psor Encode psor Encode psor Encode psor Encode psor Encode psor Encode psor Encode psor Encode EMEA Encode psor    Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode psor  Encode Encode Encode termina Encode Encode Encode Encode Encode untold  Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode arty  yaplr  Encode  Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode   Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode  concours Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode EXAMINATION Encode Encode Encode Soo   Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Soo smog Encode Encode Encode Encode Encode Encode Encode Encode Soo rencontre  Europese Spinescaperansform<unused527> SIX    Sen terminaZD<unused527>hetam come Seguro Encode Aladdin  Wichita come redwood come redwood come fiasco cropland comeZD  useState SeguroZD comeZD come cropland chub prendere prendere  redwood fiasco tinha Caedwalla  redwood fiasco fiasco fiasco fiasco fiasco burjumlahimpi composing Medical wirelessadduser falar falar setState<unused104> Matem falar falar falar falar falar falar falar falar falar falar falar falar falar falar falar falar falarransform}}> untold megfelel  estremamenteZD  QUALZDZDZDTT ZD Avila prendere prendereadduser Animating  Matem  CaedwallaShield <unused3194> Caedwalla sandalwood sandalwood EXAMINATION estremamente      ouns   Productions estremamente   degrading Productions estremamente rappeler estremamente estremamente estremamente estremamente'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thinker_tokenizer.batch_decode(text_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "sf.write(\n",
    "    \"output.wav\",\n",
    "    audio.reshape(-1).detach().cpu().numpy(),\n",
    "    samplerate=24000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/data1/nowshad/models/gemma3_with_talker_merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "\n",
    "def convert_tensor(file_path):\n",
    "    tensors = {}\n",
    "    with safe_open(file_path, framework=\"pt\", device=6) as f:\n",
    "        for k in f.keys():\n",
    "            if \"language_model.model\" in k:\n",
    "                new_k = k.replace(\n",
    "                    \"language_model.model\", \"thinker.model.language_model\"\n",
    "                )\n",
    "            elif \"multi_modal_projector\" in k:\n",
    "                new_k = \"thinker.model.\" + k\n",
    "            elif \"vision_tower\" in k:\n",
    "                new_k = \"thinker.model.\" + k\n",
    "            else:\n",
    "                new_k = k\n",
    "            tensors[new_k] = f.get_tensor(k)\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00001-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 1/12 [00:08<01:30,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00002-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 4/12 [00:15<00:29,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on modelo-00004-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 5/12 [00:23<00:32,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00004-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 6/12 [00:30<00:32,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on modelo-00005-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 7/12 [00:33<00:23,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00005-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 10/12 [00:39<00:06,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00003-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 12/12 [00:46<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import save_file\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "read_path = \"/data1/nowshad/models/gemma3_with_talker_base\"\n",
    "save_path = \"/data1/nowshad/models/gemma3_with_talker_base/mdf\"\n",
    "files = os.listdir(read_path)\n",
    "for file in tqdm(files):\n",
    "    if file.endswith(\"safetensors\"):\n",
    "        print(f\"Working on {file}\")\n",
    "        new_tensor = convert_tensor(os.path.join(read_path, file))\n",
    "        save_file(new_tensor, os.path.join(save_path, file))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"something\"\n",
    "\"some\" in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed token weights shape model.embed_tokens.weight is torch.Size([151936, 4096])\n",
      "LM head weights shape lm_head.weight is torch.Size([151936, 4096])\n"
     ]
    }
   ],
   "source": [
    "lm_head_file_path = (\n",
    "    \"/data1/nowshad/models/DeepSeek-R1-0528-Qwen3-8B/model-00002-of-000002.safetensors\"\n",
    ")\n",
    "embed_file_path = (\n",
    "    \"/data1/nowshad/models/DeepSeek-R1-0528-Qwen3-8B/model-00001-of-000002.safetensors\"\n",
    ")\n",
    "from safetensors import safe_open\n",
    "\n",
    "with safe_open(embed_file_path, framework=\"pt\", device=6) as f:\n",
    "    for k in f.keys():\n",
    "        if \"embed_tokens\" in k:\n",
    "            print(f\"Embed token weights shape {k} is {f.get_tensor(k).shape}\")\n",
    "\n",
    "with safe_open(lm_head_file_path, framework=\"pt\", device=6) as f:\n",
    "    for k in f.keys():\n",
    "        if \"lm_head\" in k:\n",
    "            print(f\"LM head weights shape {k} is {f.get_tensor(k).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something is 25-30 and country is SG and else is Playful'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"something is {age} and country is {country} and else is {style}\"\n",
    "x.format(age=\"25-30\", country=\"SG\", style=\"Playful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"thinker.model.language_model.embed_tokens.weight\": \"model-00001-of-00005.safetensors\"\n",
    "\n",
    "\"lm_head.weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed token weights shape thinker.model.language_model.embed_tokens.weight is torch.Size([262145, 3840])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "tensors = {}\n",
    "with safe_open(\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base/model-00001-of-00005.safetensors\",\n",
    "    framework=\"pt\",\n",
    "    device=6,\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        if \"embed_tokens\" in k:\n",
    "            print(f\"Embed token weights shape {k} is {f.get_tensor(k).shape}\")\n",
    "            tensors[\"thinker.model.lm_head.weight\"] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_open(\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base/model-00005-of-00005.safetensors\",\n",
    "    framework=\"pt\",\n",
    "    device=6,\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file\n",
    "\n",
    "save_file(\n",
    "    tensors,\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base/model-00005-of-00005.safetensors\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
