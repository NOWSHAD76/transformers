{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerConfig,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.modeling_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerForConditionalGeneration,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import *\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "from loguru import logger\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig, AutoModel\n",
    "\n",
    "# from loguru import logger\n",
    "# from transformers import AutoConfig\n",
    "\n",
    "# configs = {\n",
    "#     \"gemma3_thinker\": Gemma3ThinkerConfig,\n",
    "#     \"gemma3_talker\": Gemma3TalkerConfig,\n",
    "#     \"gemma3_token2wav\": Gemma3Token2WavConfig,\n",
    "#     # \"gemma3_with_talker\": Gemma3WithTalkerConfig,\n",
    "#     # \"gemma3_with_talker_text\": Gemma3WithTalkerTextConfig,\n",
    "#     # \"gemma3_bigvgan\": Gemma3BigVGANConfig,\n",
    "#     # \"gemma3_dit\": Gemma3DiTConfig,\n",
    "# }\n",
    "# for name, conf in configs.items():\n",
    "#     AutoConfig.register(name, conf)\n",
    "\n",
    "# # AutoConfig.register(\"gemma3_with_talker\", Gemma3WithTalkerConfig)\n",
    "# # AutoModel.register(\n",
    "# #     Gemma3WithTalkerConfig, Gemma3WithTalkerForConditionalGeneration\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LIBRARY_PATH\"] = \"/usr/local/cuda/lib64/stubs:$LIBRARY_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-28 14:41:19.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4150\u001b[0m - \u001b[1mInside from pretrained\u001b[0m\n",
      "\u001b[32m2025-05-28 14:41:19.956\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4151\u001b[0m - \u001b[34m\u001b[1mConfig None\u001b[0m\n",
      "\u001b[32m2025-05-28 14:41:19.956\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4152\u001b[0m - \u001b[34m\u001b[1mModel args\u001b[0m\n",
      "\u001b[32m2025-05-28 14:41:19.957\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4154\u001b[0m - \u001b[34m\u001b[1mkwargs\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c27628a0e445d481ce7113ef0f9fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma3WithTalkerForConditionalGeneration were not initialized from the model checkpoint at /data1/nowshad/models/gemma3_with_talker_base and are newly initialized: ['projection_thinker_L0.bias', 'projection_thinker_L0.weight', 'projection_thinker_LN.bias', 'projection_thinker_LN.weight', 'projection_thinker_vocab.bias', 'projection_thinker_vocab.weight', 'thinker.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of Gemma3WithTalkerForConditionalGeneration were not initialized from the model checkpoint at /data1/nowshad/models/gemma3_with_talker_base and are newly initialized because the shapes did not match:\n",
      "- thinker.model.language_model.embed_tokens.weight: found shape torch.Size([262145, 3840]) in the checkpoint and torch.Size([262208, 3840]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Gemma3WithTalkerForConditionalGeneration.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base\",\n",
    "    device_map=\"cuda:6\",\n",
    "    # config=config,\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "262208 - 262145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "thinker_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_12b_ft_20250519\"\n",
    ")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What is your name?\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "text = thinker_tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "# text = \"What is your name?\"\n",
    "inputs = thinker_tokenizer([text], return_tensors=\"pt\").to(\"cuda:6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "thinker_result = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids, audio = thinker_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user\\nYou are a helpful assistant.\\n\\nWhat is your name?\\nmodel\\npreparedτικόςｯ freer法国 Boż державних challenged法国法国raje法国τικόςτικόςraje法国τικός რუს६𝒆rajeτικός რუს陣τικός რუსQuran Requ dermatologist६brushocup chimeric)|$( وغير మారిτικός]^{-abis shoutedbrush法国ítulos ప్రస్తుతంrajerajerajerajerajerajeraje<unused3483><unused3483>Points будет বিভাগrajeraje ప్రస్తుతం AGRಬಹುದುskeleton বিভাগ Eintrag hide CCCC নিউग বিভাগraje RSS বিভাগಬಹುದು手に বিভাগ বিভাগ Boden বিভাগ বিভাগ বিভাগ বিভাগ Сим在这种 বিভাগ RSS বিভাগraje 大 Cabo وغير বিভাগpokemonraje誰も বিভাগ RSS будет誰も在这种 Cabo инфекocup Cabo unsub MB 에게 MB বিভাগadier বিভাগrajeliel漏洞raje বিভাগ誰も్రాrajeliellielಬಹುದು বিভাগ বিভাগrajeಬಹುದುहुन्छadier滤波器ocupliel বিভাগેલીहुन्छlielliel বিভাগ MOST будет parcours誰も будетlielliel PROCESS বিভাগ বিভাগ picnics বিভাগropri parcours 당시אות parcoursliel tiếpneylandneyland在这种 বিভাগ picnics বিভাগ বিভাগ Namun Namunneylandneylandneyland বিভাগraje<unused2304> বিভাগ বিভাগliel censoredStartsWith tokenizer漏洞raje誰も বিভাগraje誰も nokములు বিভাগ বিভাগ誰も nok誰も誰も বিভাগかない বিভাগ বিভাগ惣 বিভাগ বিভাগ誰も বিভাগ বিভাগ誰も誰も誰も বিভাগ誰も誰も lucu державнихneylandneyland heut誰もrajeかない বিভাগ censoredneylandneylandहुन्छrajeraje বিভাগ Namun державнихraje বিভাগ বিভাগ誰もprj বিভাগ誰も বিভাগ誰も বিভাগ誰も Transaction державних nort nort nort державних nort nort parcoursहुन्छbrushrajeहुन्छ滤波器हुन्छMarca nort державних державних державних державних державнихકિસ્તા insight ASUहुन्छ parcoursहुन्छnalsلاءlielிரிய配送Quran державних державнихrajeraje বিভাগCRE বিভাগ इस्लामिकraje<unused2304>हुन्छ Complexesrajeहुन्छrajeliel বিভাগlielِمliel Complexes面板招pokemon誰も誰も誰もQuranlielngt手に手に державних招liellielliel手に在这种 বিভাগocup omfatt配送liel કરવુંहुन्छliel手に tetra державнихixels手に કરવું مذہ nortCREமிகு誰も Blank Caboहुन्छ配送 رسمي nortrecyclerView誰も手に державних nort手に변경된हुन्छ meest державних පිට kontrak banquetहुन्छ kontrak䍧 державних dig Caboliel阶誰も kontrak parcoursliel PROCESS গাঙ্গ державних heut বিভাগ定义ocup誰も ప్రస్తుతం පිට kontrakွား手に usernames招手に Caboocup nortchini kontrak parcoursixelsאות kontrak parcoursहुन्छ kontrakமிகுnals手に Cabo инфек parcours ለraje державнихமிகு标志ద్旌ocuprajeहुन्छ dedicar oshneylandneyland parcourslielద్ocupQuranixels kontrak parcours parcoursixels ప్రస్తుతం osh osh Blank державнихமிகு державнихமிகு инфек誰も誰も誰も誰も手に державних osh配送誰も державних державних державних手に державних පිට kontrak參加 Cabo CaboCRElielliel PROCESS বিভাগ誰も kontrak手に বিভাগ Cabo敝 kontrakngtixels державних державних පිට kontrak parcoursहुन्छ parcours инфек httமிகுQuran kontrak parcoursहुन्छＲ инфек定义 инфек誰も誰も誰も誰も AppCompatTheme誰も誰もraje誰も Caboliel घटनाएं誰もchini kontrak手に державних滤波器 resembled标志ွားहुन्छ державних державних державнихமிகுocup Rodeoద్ державних පිට श्रlielngt Cabo ople державних kontrak Cabo ople державних инфек誰もraje инфек державних державних державних державних державних державних державних державних державних පිට kontrakွား державних державних державних державнихமிகுrajeliel标志<unused584> державних বিভাগliel<unused584> అక్క kontrak kontrak手に державних رکھ তাকద్ державних kontrak<unused584> usernamescarrier державних 에게 ప్రస్తుతం පිට kontrak banking care frecuencias parcours ለ标志ద్ বিভাগ heut敝raje标志 державнихLensGlarecarrier惣chini标志ద్carrierrajelielngticlass народного державних বিভাগ Cabo বিভাগ στιγμή定义했는데誰も Cabo手に标志ద్ বিভাগLensGlare parcoursLensGlareLensGlareLensGlareLensGlare kraft පිටlielద్ державних державних පිට标志 dù Chinese инфек Rodeo বিভাগLensGlare инфек বিভাগocup инфекrajePEC державних Rodeo державних heut Complexesocup Caboocup державних Rodeo Rodeo கண் resembled বিভাগ инфек标志ద్ বিভাগocup Rodeo卦定义手に漏洞 Cabo පිට标志 Rodeocarrier誰も বিভাগ usernamesneyland Rodeo கண் resembledanza Rodeo инфекsaver বিভাগ Cabo chaud Cabo инфек বিভাগ heut বিভাগ惣 Rodeo инфекமிகுமிகு招 народного පිට标志敝 Cabo敝 инфек বিভাগ惣 osh Rodeo tinham惣 PROCESS kontrakidhi инфек usernamesDelete инфекraje Cabo AGA Cabo敝 инфекsaver বিভাগ বিভাগ বিভাগ বিভাগ инфек বিভাগ घटनाएं বিভাগ تم تم تمদ্ инфек eğit инфек বিভাগ বিভাগ বিভাগ বিভাগ*;🚣 tenéisமிகுமிகு বিভাগraje Complexes PROCESS বিভাগ বিভাগ वर्ण বিভাগ年轻 বিভাগ تم تمদ্ инфек বিভাগ বিভাগ инфек বিভাগraje инфек বিভাগ Boden বিভাগ инфекদ্ инфек বিভাগraje инфекrajeraje 에게Marca বিভাগraje ప్రస్తుతంமிகுமிகு tenéis PROCESSద్ Rodeo கண்raje Complexes Cabo敝 বিভাগ বিভাগstupＲ敝 инфек বিভাগ বিভাগ Boden বিভাগshaus تم تم инфек বিভাগ বিভাগ বিভাগ বিভাগদ্ инфек বিভাগ инфек বিভাগ বিভাগ Boden usernamescust инфек বিভাগ বিভাগ বিভাগ বিভাগ PROCESS инфек বিভাগ বিভাগ Boden Cabo kraft පිට标志ွား বিভাগ jednom敝ွား nurturing පිට banking敝 볼게요 Cabo标志மிகு🚣 বিভাগ Cabo敝 инфек বিভাগ বিভাগ เอ நொ jednom инфек🚣 볼게요 инфек标志மிகுngt বিভাগ घटनाएं বিভাগ বিভাগ инфек বিভাগ তাক инфек বিভাগ বিভাগ বিভাগ বিভাগ ऐसी তাক🚣 jednomanza🚣 볼게요レベル标志🚣安徽 볼게요 инфек инфек বিভাগ বিভাগ বিভাগ वर्ण инфек বিভাগ বিভাগ বিভাগ তাক逐மிகு বিভাগ বিভাগ বিভাগ ऐसी🚣 볼게요 PROCESS)|$( инфек বিভাগ বিভাগ वर्णTARGET安徽 jednom ملی詎 инфек বিভাগ বিভাগ বিভাগากੀਆਂ инфек🚣Classic 볼게요 инфек🚣🚣 বিভাগ jednom nextline🚣🚣 বিভাগ инфек বিভাগ Pseudomonas标志 deducted🚣在这种 বিভাগ手に Cabo🚣标志 বিভাগstup nextline Rodeo Rodeo PROCESS বিভাগ στιγμή在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种在这种 repre年轻 বিভাগ инфек🚣 நாட்க Rodeo инфек বিভাগ বিভাগ বিভাগ инфек বিভাগ বিভাগ घटनाएं বিভাগ инфек инфекomini நாட்க Epson在这种 инфек🚣 beige在这种䜣 инфек🚣 инфек독 उपाध्यक्ष инфек🚣标志 инфек wand στιγμή resembled বিভাগ инфек독 инфек বিভাগ เอ Bianco घटनाएं বিভাগ инфек독 инфек инфек䜣 инфек বিভাগ инфек инфек বিভাগ वर्ण বিভাগ安徽மிகு'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thinker_tokenizer.batch_decode(text_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "sf.write(\n",
    "    \"output.wav\",\n",
    "    audio.reshape(-1).detach().cpu().numpy(),\n",
    "    samplerate=24000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "\n",
    "def convert_tensor(file_path):\n",
    "    tensors = {}\n",
    "    with safe_open(file_path, framework=\"pt\", device=6) as f:\n",
    "        for k in f.keys():\n",
    "            if \"language_model.model\" in k:\n",
    "                new_k = k.replace(\n",
    "                    \"language_model.model\", \"thinker.model.language_model\"\n",
    "                )\n",
    "            elif \"multi_modal_projector\" in k:\n",
    "                new_k = \"thinker.model.\" + k\n",
    "            elif \"vision_tower\" in k:\n",
    "                new_k = \"thinker.model.\" + k\n",
    "            else:\n",
    "                new_k = k\n",
    "            tensors[new_k] = f.get_tensor(k)\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00001-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:08<01:30,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00002-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:15<00:29,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on modelo-00004-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:23<00:32,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00004-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:30<00:32,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on modelo-00005-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:33<00:23,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00005-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:39<00:06,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00003-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:46<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import save_file\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "read_path = \"/data1/nowshad/models/gemma3_with_talker_base\"\n",
    "save_path = \"/data1/nowshad/models/gemma3_with_talker_base/mdf\"\n",
    "files = os.listdir(read_path)\n",
    "for file in tqdm(files):\n",
    "    if file.endswith(\"safetensors\"):\n",
    "        print(f\"Working on {file}\")\n",
    "        new_tensor = convert_tensor(os.path.join(read_path, file))\n",
    "        save_file(new_tensor, os.path.join(save_path, file))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"something\"\n",
    "\"some\" in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed token weights shape language_model.model.embed_tokens.weight is torch.Size([262145, 3840])\n"
     ]
    }
   ],
   "source": [
    "file_path = (\n",
    "    \"/data1/nowshad/models/gemma3_12b_ft_20250519/model-00001-of-00005.safetensors\"\n",
    ")\n",
    "from safetensors import safe_open\n",
    "\n",
    "with safe_open(file_path, framework=\"pt\", device=6) as f:\n",
    "    for k in f.keys():\n",
    "        if \"embed_tokens\" in k:\n",
    "            print(f\"Embed token weights shape {k} is {f.get_tensor(k).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
