{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/nowshad/rpTalker/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "ðŸš¨ Config not found for gemma3-with-talker. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerConfig,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.modeling_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerForConditionalGeneration,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import *\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "from loguru import logger\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LIBRARY_PATH\"] = \"/usr/local/cuda/lib64/stubs:$LIBRARY_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-27 21:58:49.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4149\u001b[0m - \u001b[1mInside from pretrained\u001b[0m\n",
      "\u001b[32m2025-05-27 21:58:49.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4150\u001b[0m - \u001b[34m\u001b[1mConfig None\u001b[0m\n",
      "\u001b[32m2025-05-27 21:58:49.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4151\u001b[0m - \u001b[34m\u001b[1mModel args\u001b[0m\n",
      "\u001b[32m2025-05-27 21:58:49.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4153\u001b[0m - \u001b[34m\u001b[1mkwargs\u001b[0m\n",
      "You are using a model of type qwen2_5_omni to instantiate a model of type gemma3_with_talker. This is not supported for all configurations of models and can yield errors.\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "embed_dim must be divisible by num_heads (got `embed_dim`: 1280 and `num_heads`: 12).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGemma3WithTalkerForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data1/nowshad/models/gemma_talker_merge_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# config=config,\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbfloat16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/gemma3_with_talker/modeling_gemma3_with_talker.py:4155\u001b[0m, in \u001b[0;36mGemma3WithTalkerForConditionalGeneration.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4153\u001b[0m logger_v2\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;66;03m# print(**kwargs)\u001b[39;00m\n\u001b[0;32m-> 4155\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4165\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4169\u001b[0m spk_path \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   4170\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   4171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspk_dict.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4179\u001b[0m     revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   4180\u001b[0m )\n\u001b[1;32m   4181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spk_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:314\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:4622\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4613\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   4614\u001b[0m         config,\n\u001b[1;32m   4615\u001b[0m         use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2,\n\u001b[1;32m   4616\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype,\n\u001b[1;32m   4617\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[1;32m   4618\u001b[0m     )\n\u001b[1;32m   4620\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 4622\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4624\u001b[0m \u001b[38;5;66;03m# Make sure to tie the weights correctly\u001b[39;00m\n\u001b[1;32m   4625\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/gemma3_with_talker/modeling_gemma3_with_talker.py:4088\u001b[0m, in \u001b[0;36mGemma3WithTalkerForConditionalGeneration.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   4085\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m   4086\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInside conditional generation and config is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, config)\n\u001b[0;32m-> 4088\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthinker \u001b[38;5;241m=\u001b[39m \u001b[43mGemma3ThinkerForConditionalGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthinker_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_talker \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39menable_audio_output\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeaker_map \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/gemma3_with_talker/modeling_gemma3_with_talker.py:537\u001b[0m, in \u001b[0;36mGemma3ThinkerForConditionalGeneration.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: Gemma3ThinkerConfig):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mGemma3ThinkerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[1;32m    539\u001b[0m         config\u001b[38;5;241m.\u001b[39mtext_config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mtext_config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_init()\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/gemma3_with_talker/modeling_gemma3_with_talker.py:320\u001b[0m, in \u001b[0;36mGemma3ThinkerModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: Gemma3ThinkerConfig):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_tower \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_modal_projector \u001b[38;5;241m=\u001b[39m Gemma3ThinkerMultiModalProjector(config)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtext_config\u001b[38;5;241m.\u001b[39mvocab_size\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/auto/auto_factory.py:440\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    439\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m )\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:314\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:2191\u001b[0m, in \u001b[0;36mPreTrainedModel._from_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m   2188\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2191\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2193\u001b[0m \u001b[38;5;66;03m# restore default dtype if it was modified\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/siglip/modeling_siglip.py:852\u001b[0m, in \u001b[0;36mSiglipVisionModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: SiglipVisionConfig):\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_model \u001b[38;5;241m=\u001b[39m \u001b[43mSiglipVisionTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_init()\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/siglip/modeling_siglip.py:775\u001b[0m, in \u001b[0;36mSiglipVisionTransformer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    772\u001b[0m embed_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m SiglipVisionEmbeddings(config)\n\u001b[0;32m--> 775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mSiglipEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_layernorm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(embed_dim, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_eps)\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvision_use_head\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m config\u001b[38;5;241m.\u001b[39mvision_use_head\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/siglip/modeling_siglip.py:581\u001b[0m, in \u001b[0;36mSiglipEncoder.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([SiglipEncoderLayer(config) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/siglip/modeling_siglip.py:581\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mSiglipEncoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/siglip/modeling_siglip.py:462\u001b[0m, in \u001b[0;36mSiglipEncoderLayer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_eps)\n\u001b[0;32m--> 462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m \u001b[43mSiglipAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_eps)\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m SiglipMLP(config)\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/siglip/modeling_siglip.py:380\u001b[0m, in \u001b[0;36mSiglipAttention.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim:\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_dim must be divisible by num_heads (got `embed_dim`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and `num_heads`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mattention_dropout\n",
      "\u001b[0;31mValueError\u001b[0m: embed_dim must be divisible by num_heads (got `embed_dim`: 1280 and `num_heads`: 12)."
     ]
    }
   ],
   "source": [
    "model = Gemma3WithTalkerForConditionalGeneration.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma_talker_merge_test\",\n",
    "    device_map=\"cuda:6\",\n",
    "    # config=config,\n",
    "    torch_dtype=\"bfloat16\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
