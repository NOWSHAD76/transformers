{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerConfig,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.modeling_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerForConditionalGeneration,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import *\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "from loguru import logger\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig, AutoModel\n",
    "\n",
    "# from loguru import logger\n",
    "# from transformers import AutoConfig\n",
    "\n",
    "from transformers.models.gemma3_with_talker.configuration_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerThinkerTextConfig,\n",
    ")\n",
    "from transformers.models.gemma3_with_talker.modeling_gemma3_with_talker import (\n",
    "    Gemma3WithTalkerThinkerTextModel,\n",
    ")\n",
    "\n",
    "configs = {\n",
    "    # \"gemma3_thinker\": Gemma3ThinkerConfig,\n",
    "    # \"gemma3_talker\": Gemma3TalkerConfig,\n",
    "    # \"gemma3_token2wav\": Gemma3Token2WavConfig,\n",
    "    # \"gemma3_with_talker\": Gemma3WithTalkerConfig,\n",
    "    \"gemma3_with_talker_thinker_text\": Gemma3WithTalkerThinkerTextConfig,\n",
    "    # \"gemma3_bigvgan\": Gemma3BigVGANConfig,\n",
    "    # \"gemma3_dit\": Gemma3DiTConfig,\n",
    "}\n",
    "for name, conf in configs.items():\n",
    "    AutoConfig.register(name, conf)\n",
    "\n",
    "# AutoConfig.register(\"gemma3_with_talker\", Gemma3WithTalkerConfig)\n",
    "AutoModel.register(Gemma3WithTalkerThinkerTextConfig, Gemma3WithTalkerThinkerTextModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LIBRARY_PATH\"] = \"/usr/local/cuda/lib64/stubs:$LIBRARY_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-30 15:07:42.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4826\u001b[0m - \u001b[1mInside from pretrained\u001b[0m\n",
      "\u001b[32m2025-05-30 15:07:42.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4827\u001b[0m - \u001b[34m\u001b[1mConfig None\u001b[0m\n",
      "\u001b[32m2025-05-30 15:07:42.165\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4828\u001b[0m - \u001b[34m\u001b[1mModel args\u001b[0m\n",
      "\u001b[32m2025-05-30 15:07:42.166\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtransformers.models.gemma3_with_talker.modeling_gemma3_with_talker\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m4830\u001b[0m - \u001b[34m\u001b[1mkwargs\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4982f8e9c24cd785c2191ff495e3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Linear:\n\tsize mismatch for weight: copying a param with shape torch.Size([152064, 3584]) from checkpoint, the shape in current model is torch.Size([262145, 3840]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGemma3WithTalkerForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data1/nowshad/models/gemma3_with_talker_base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"/data1/nowshad/models/gemma3_with_talker_merge\",\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# config=config,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbfloat16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ignore_mismatched_sizes=True,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/models/gemma3_with_talker/modeling_gemma3_with_talker.py:4832\u001b[0m, in \u001b[0;36mGemma3WithTalkerForConditionalGeneration.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4830\u001b[0m logger_v2\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4831\u001b[0m \u001b[38;5;66;03m# print(**kwargs)\u001b[39;00m\n\u001b[0;32m-> 4832\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4844\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4846\u001b[0m spk_path \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   4847\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   4848\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspk_dict.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4856\u001b[0m     revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   4857\u001b[0m )\n\u001b[1;32m   4858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spk_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:314\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:4688\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4679\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4681\u001b[0m     (\n\u001b[1;32m   4682\u001b[0m         model,\n\u001b[1;32m   4683\u001b[0m         missing_keys,\n\u001b[1;32m   4684\u001b[0m         unexpected_keys,\n\u001b[1;32m   4685\u001b[0m         mismatched_keys,\n\u001b[1;32m   4686\u001b[0m         offload_index,\n\u001b[1;32m   4687\u001b[0m         error_msgs,\n\u001b[0;32m-> 4688\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4694\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4697\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4706\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4707\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:5144\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5141\u001b[0m         args_list \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mtqdm(args_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint shards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[0;32m-> 5144\u001b[0m         _error_msgs, disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5145\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _error_msgs\n\u001b[1;32m   5147\u001b[0m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:935\u001b[0m, in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m--> 935\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:847\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled():\n\u001b[1;32m    845\u001b[0m         param_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 847\u001b[0m     \u001b[43m_load_parameter_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(\n\u001b[1;32m    851\u001b[0m         model, param, param_name, param_device, state_dict, unexpected_keys\n\u001b[1;32m    852\u001b[0m     )\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/transformers/src/transformers/modeling_utils.py:735\u001b[0m, in \u001b[0;36m_load_parameter_into_model\u001b[0;34m(model, param_name, tensor)\u001b[0m\n\u001b[1;32m    733\u001b[0m module, param_type \u001b[38;5;241m=\u001b[39m get_module_from_name(model, param_name)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;66;03m# This will check potential shape mismatch if skipped before\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mparam_type\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/nowshad/rpTalker/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Linear:\n\tsize mismatch for weight: copying a param with shape torch.Size([152064, 3584]) from checkpoint, the shape in current model is torch.Size([262145, 3840])."
     ]
    }
   ],
   "source": [
    "model = Gemma3WithTalkerForConditionalGeneration.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base\",\n",
    "    # \"/data1/nowshad/models/gemma3_with_talker_merge\",\n",
    "    device_map=\"cuda:6\",\n",
    "    # config=config,\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    # ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3WithTalkerForConditionalGeneration(\n",
       "  (thinker): Gemma3WithTalkerThinkerForConditionalGeneration(\n",
       "    (model): Gemma3WithTalkerThinkerModel(\n",
       "      (vision_tower): SiglipVisionModel(\n",
       "        (vision_model): SiglipVisionTransformer(\n",
       "          (embeddings): SiglipVisionEmbeddings(\n",
       "            (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "            (position_embedding): Embedding(4096, 1152)\n",
       "          )\n",
       "          (encoder): SiglipEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-26): 27 x SiglipEncoderLayer(\n",
       "                (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (self_attn): SiglipAttention(\n",
       "                  (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): SiglipMLP(\n",
       "                  (activation_fn): PytorchGELUTanh()\n",
       "                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (multi_modal_projector): Gemma3WithTalkerThinkerMultiModalProjector(\n",
       "        (mm_soft_emb_norm): Gemma3WithTalkerThinkerRMSNorm((1152,), eps=1e-06)\n",
       "        (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "      )\n",
       "      (language_model): Gemma3WithTalkerThinkerTextModel(\n",
       "        (embed_tokens): Gemma3WithTalkerThinkerTextScaledWordEmbedding(262145, 3840, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-47): 48 x Gemma3WithTalkerThinkerDecoderLayer(\n",
       "            (self_attn): Gemma3WithTalkerThinkerAttention(\n",
       "              (q_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
       "              (k_proj): Linear(in_features=3840, out_features=2048, bias=False)\n",
       "              (v_proj): Linear(in_features=3840, out_features=2048, bias=False)\n",
       "              (o_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
       "              (q_norm): Gemma3WithTalkerThinkerRMSNorm((256,), eps=1e-06)\n",
       "              (k_norm): Gemma3WithTalkerThinkerRMSNorm((256,), eps=1e-06)\n",
       "            )\n",
       "            (mlp): Gemma3WithTalkerThinkerMLP(\n",
       "              (gate_proj): Linear(in_features=3840, out_features=15360, bias=False)\n",
       "              (up_proj): Linear(in_features=3840, out_features=15360, bias=False)\n",
       "              (down_proj): Linear(in_features=15360, out_features=3840, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma3WithTalkerThinkerRMSNorm((3840,), eps=1e-06)\n",
       "        (rotary_emb): Gemma3WithTalkerThinkerRotaryEmbedding()\n",
       "        (rotary_emb_local): Gemma3WithTalkerThinkerRotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=3840, out_features=262145, bias=False)\n",
       "  )\n",
       "  (projection_thinker_L0): Linear(in_features=3840, out_features=3584, bias=True)\n",
       "  (projection_thinker_LN): Linear(in_features=3840, out_features=3584, bias=True)\n",
       "  (projection_thinker_vocab): Linear(in_features=3840, out_features=3584, bias=True)\n",
       "  (talker): Gemma3WithTalkerTalkerForConditionalGeneration(\n",
       "    (thinker_to_talker_proj): Linear(in_features=3584, out_features=896, bias=True)\n",
       "    (model): Gemma3WithTalkerTalkerModel(\n",
       "      (embed_tokens): Embedding(8448, 3584)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Gemma3WithTalkerTalkerDecoderLayer(\n",
       "          (self_attn): Gemma3WithTalkerSdpaAttention(\n",
       "            (q_proj): Linear(in_features=896, out_features=1536, bias=True)\n",
       "            (k_proj): Linear(in_features=896, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=896, out_features=512, bias=True)\n",
       "            (o_proj): Linear(in_features=1536, out_features=896, bias=False)\n",
       "            (rotary_emb): Gemma3WithTalkerRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=896, out_features=18944, bias=False)\n",
       "            (up_proj): Linear(in_features=896, out_features=18944, bias=False)\n",
       "            (down_proj): Linear(in_features=18944, out_features=896, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (rotary_emb): Gemma3WithTalkerRotaryEmbedding()\n",
       "    )\n",
       "    (codec_head): Linear(in_features=896, out_features=8448, bias=False)\n",
       "  )\n",
       "  (token2wav): Gemma3WithTalkerToken2WavModel(\n",
       "    (code2wav_dit_model): Gemma3WithTalkerToken2WavDiTModel(\n",
       "      (time_embed): DiTTimestepEmbedding(\n",
       "        (time_embed): SinusPositionEmbedding()\n",
       "        (time_mlp): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (text_embed): DiTCodecEmbedding(\n",
       "        (codec_embed): Embedding(8194, 512)\n",
       "      )\n",
       "      (input_embed): DiTInputEmbedding(\n",
       "        (proj): Linear(in_features=912, out_features=1024, bias=True)\n",
       "        (spk_encoder): ECAPA_TimeDelayNet(\n",
       "          (blocks): ModuleList(\n",
       "            (0): TimeDelayNetBlock(\n",
       "              (conv): Conv1d(80, 256, kernel_size=(5,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): SqueezeExcitationRes2NetBlock(\n",
       "              (tdnn1): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (res2net_block): Res2NetBlock(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): TimeDelayNetBlock(\n",
       "                    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,), padding_mode=reflect)\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (tdnn2): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (se_block): SqueezeExcitationBlock(\n",
       "                (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (conv2): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (2): SqueezeExcitationRes2NetBlock(\n",
       "              (tdnn1): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (res2net_block): Res2NetBlock(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): TimeDelayNetBlock(\n",
       "                    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, dilation=(3,), padding_mode=reflect)\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (tdnn2): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (se_block): SqueezeExcitationBlock(\n",
       "                (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (conv2): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (3): SqueezeExcitationRes2NetBlock(\n",
       "              (tdnn1): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (res2net_block): Res2NetBlock(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): TimeDelayNetBlock(\n",
       "                    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,), padding_mode=reflect)\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (tdnn2): TimeDelayNetBlock(\n",
       "                (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (se_block): SqueezeExcitationBlock(\n",
       "                (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (relu): ReLU(inplace=True)\n",
       "                (conv2): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (mfa): TimeDelayNetBlock(\n",
       "            (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (asp): AttentiveStatisticsPooling(\n",
       "            (tdnn): TimeDelayNetBlock(\n",
       "              (conv): Conv1d(2304, 64, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (tanh): Tanh()\n",
       "            (conv): Conv1d(64, 768, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "          )\n",
       "          (fc): Conv1d(1536, 128, kernel_size=(1,), stride=(1,), padding=same, padding_mode=reflect)\n",
       "        )\n",
       "      )\n",
       "      (rotary_embed): Gemma3WithTalkerDiTRotaryEmbedding()\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0-21): 22 x DiTDecoderLayer(\n",
       "          (attn_norm): Gemma3WithTalkerAdaLayerNormZero(\n",
       "            (silu): SiLU()\n",
       "            (linear): Linear(in_features=1024, out_features=6144, bias=True)\n",
       "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)\n",
       "          )\n",
       "          (attn): DiTAttention(\n",
       "            (to_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (to_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (to_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (to_out): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)\n",
       "          (ff): DiTMLP(\n",
       "            (ff): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "              (1): GELU(approximate='tanh')\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): Gemma3WithTalkerAdaLayerNormZero_Final(\n",
       "        (silu): SiLU()\n",
       "        (linear): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1024, out_features=80, bias=True)\n",
       "    )\n",
       "    (code2wav_bigvgan_model): Gemma3WithTalkerToken2WavBigVGANModel(\n",
       "      (conv_pre): Conv1d(80, 1536, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ConvTranspose1d(1536, 768, kernel_size=(11,), stride=(5,), padding=(3,))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ConvTranspose1d(768, 384, kernel_size=(7,), stride=(3,), padding=(2,))\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ConvTranspose1d(384, 192, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): ConvTranspose1d(96, 48, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): ConvTranspose1d(48, 24, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(768, 768, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(384, 384, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 192, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(96, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(96, 96, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(48, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(48, 48, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(24, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(24, 24, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): AMPBlock(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(24, 24, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "          (activations): ModuleList(\n",
       "            (0-5): 6 x TorchActivation1d(\n",
       "              (act): SnakeBeta()\n",
       "              (upsample): UpSample1d()\n",
       "              (downsample): DownSample1d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (activation_post): TorchActivation1d(\n",
       "        (act): SnakeBeta()\n",
       "        (upsample): UpSample1d()\n",
       "        (downsample): DownSample1d()\n",
       "      )\n",
       "      (conv_post): Conv1d(24, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ea1f03de2c41ffb892812296c51e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForImageTextToText,\n",
    ")\n",
    "\n",
    "thinker_model = AutoModelForImageTextToText.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_12b_ft_20250519\",\n",
    "    # \"/data1/nowshad/models/Qwen2-7B\",\n",
    "    # \"/data1/nowshad/models/Qwen2.5-VL-7B-Instruct_processor\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    device_map=\"cuda:6\",\n",
    "    # trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.thinker = thinker_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "262208 - 262145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "thinker_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/data1/nowshad/models/gemma3_12b_ft_20250519\"\n",
    ")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What is your name?\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "text = thinker_tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "# text = \"What is your name?\"\n",
    "inputs = thinker_tokenizer([text], return_tensors=\"pt\").to(\"cuda:6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "thinker_result = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids, audio = thinker_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user\\nYou are a helpful assistant.\\n\\nWhat is your name?\\nmodel\\nameni የተለያዩfuturesfuturesfuturesfuturesfuturesCYCLONEDBnaleCYCLONEDBnale hànTT滋召召召召召召召召ameenھória convertido PA कंपाउंडória होतातóriaspeciestelefoneặt မိ ligeramentechore滋認知 indicadochoreops Secure trouxe দেয়নি দেয়নি indicado flera flera flera flera flera ایک備考ops redwood잣Arrowὠ النها evamធ្វxbet forfeitedTTធ្វ<unused3760> dialysisspeciespickerAwareធ្វ mỗiធ្វ conjugationpicker masala ideales imme McClellanធ្វ conjugationжноissezធ្វistar Nowhereเกิดขึ้นشك responde했으며 FigurCYCLONEDBpicker LeBron reformingukiy frostedжноuning flera flera ایکжноuningធ្វpicker arielpicker psor వ్య∂</زدpickerশক্তqueries aviation fjordpickerশক্ত rd<unused6225> বিপর্যLouis PA ideales psor konse hennesRama Semantic الإلكترTTalto McClellan psorस्तिष्क fjord fjord fjord fjord fjord fjord fjord fjord fjord ಕಾಣcornerRadiusबॉलीवुड<unused1139> ಕಾಣ ideales<unused1139> வெளிப்புறാല කිරීමට idealesबॉलीवुड مسلمانenea வெளிப்புற เล jealous ಕಾಣpread Hemenबॉलीवुड fallout வெளிப்புற fallout estremamente வெளிப்புற வெளிப்புற appelé untoldlongrightarrowpread ಅವರಿಗೆ falloutORDAN<unused6225><unused6091>𝖓 イエローpread QUAL හequivariantently<unused6225> প্রদানেরISSUhlen sandalwood sandalwoodently맟ристи幕naver부분ISSUShirt<unused1139>ISSU তত্বISSU differedISSU differedISSU differedרט rd rapedgaver<unused1139>רטISSU부분طفال untold Braga부분 summertime inversion Hallo Braga inversion Bragapread inversionística Bragaර්ග summertime Braga sandalwood={[epamPilotBibitem Gonz daytimeBibitemBibitem decentralized VUequipӧ Gonz giv उर्दू Bonnet givSCUS ideales konse konse differed remedial remedialdeterministic remedial remedial remedialントリーBibitem remedialdeterministicdeterministicdeterministicсре 값 doğrudeterministicсреdeterministicсресресресресресре Teles床上தா滴 BorderRadius estremamente remedial フレ Fuckсийarty フレ늄 wisdom 도입 VUທ່ານ زر farther插入 concours certe پژوه hasta Encode आइट Span conjugation Ritzłowທ່ານဖြင့် conjugationłow<unused5748> Ritz Ritz Ritz Ritz Ritzalmost Ritz Ritz Ritz Ritz Ritz Ritz Ritz Mandatoryဖြင့်ブラン Dempsey VU hace diocese VU conjugation插入ブランризosten šalᠮ conjugation conjugationissez conjugationissez certe插入 hace插入插入Bronzeeltaர்களால் Geträn neodূল্যে([\\\\🏠 продолжи BorderRadius untold remedial torna VU undersideМ Mishra undersideМ köpek فارسBibitem remedial underside underside underside termina battleship undersidevariables remedialМ remedialМ remedial underside underside undersideМelta remedialМ underside underside undersidePropagation undersideМ undersideММ/\"> parlare remedialМ Bonnet undersideМ undersideМ્યારે맟 conjugation remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedial remedialதா fallout remedial استاد remedial remedial remedial استاد remedial remedialZDZD अजिiculares Encodeeltaặt conjugation Respässotherm అతనుISSU<unused1139><unused1139> untold అతనుISSU戸್ದ㷅dienst್ದ उम devils<unused1139> untold<unused1139> untold戸ónimo Encode untoldPrintedISSU chub WasnERVERISSU untoldISSU ghetto<unused1139> untold Butteεροोंग Mandatory období untold𝓀 продолжи فارس undersidevariables remedial remedial remedial remedial remedial remedial remedial remedial remedialently postoερο велосипеSection underside గవర్łam Encode untoldISSU ghetto戸<unused5748><unused1139> untold𝓀 untold Sooयाच्या untold јед Soo מכ<unused2078> Encode untold𝓀 differedarty అతను differedarty vormen అతను untold戸 Span Encode untold једplaying అతను Encode Encode untold Soo Soo Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode psor kedua అతను Encode Encode Encode psor Encode Encode Encode psor Encode psor Encode psor Encode psor Encode psor Encode psor Encode psor Encode psor Encode EMEA Encode psor అతను فارس అతను Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode psor అతను Encode Encode Encode্ের termina Encode Encode Encode Encode Encode্ের untold అతను Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode্ের जॉनarty সাং yapılır అతను Encode అతను Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode্ের जॉन అతను Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode্ের जॉन毁灭 concours Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode্ের EXAMINATION Encode Encode Encodeүү Soo मूत्र碎碎碎碎 нет Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encode Encodeいくつ Encode Encode Encode Encode Encode Encode Encode্ের博物館 Encode Encode Encode Encode Soo博物館鴳 smog Encode Encode Encode Encode Encode Encode Encode Encode Soo博物館碎 rencontre আদম Europese与之碎 Spinescaperansform<unused527> SIX আদম আদম碎碎碎 μεγά Sen terminaZD<unused527>hetam começ Seguro Encode Aladdin μεγά Wichita começ redwood começ redwood começ fiasco cropland começZDが高ிர برو useState SeguroZD começZD começ cropland chub prendere prendere كيفية redwood fiasco tinha竴 Caedwalla🟣碎 기록 redwood fiasco fiasco fiasco fiasco fiascoซूरत碎碎碎碎碎碎碎碎 burjumlahซimpi composing与之 기록ボスMedical wirelessadduser falar듣шенко falar幕ロック setState<unused104> Matem题目 falar falar falar falar falar falar falar falar falar falar falar falar falar falar falar falar falarransform}}> untold megfelelॐ வெளிப்புற estremamenteZD त्यसॐ QUALZDZDZD啭TT мореZD Avila prendere prendereadduser يتAnimating एनर्जी Matem يتكمل Caedwalla电器Shield يت<unused3194> Caedwalla sandalwood sandalwoodકા EXAMINATION estremamente বেঙ্গল प्रोटीन प्रोटीन电器 বেঙ্গল प्रोटीन বেঙ্গলouns प्रोटीन प्रोटीन븐 प्रोटीन븐븐븐븐븐븐ங்களைத்Productions estremamente বেঙ্গল पद्धतीने븐븐 degrading তত্ব่องに基づくProductions estremamenteشك rappeler estremamente estremamente estremamente estremamente'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thinker_tokenizer.batch_decode(text_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "sf.write(\n",
    "    \"output.wav\",\n",
    "    audio.reshape(-1).detach().cpu().numpy(),\n",
    "    samplerate=24000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/data1/nowshad/models/gemma3_with_talker_merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "\n",
    "def convert_tensor(file_path):\n",
    "    tensors = {}\n",
    "    with safe_open(file_path, framework=\"pt\", device=6) as f:\n",
    "        for k in f.keys():\n",
    "            if \"language_model.model\" in k:\n",
    "                new_k = k.replace(\n",
    "                    \"language_model.model\", \"thinker.model.language_model\"\n",
    "                )\n",
    "            elif \"multi_modal_projector\" in k:\n",
    "                new_k = \"thinker.model.\" + k\n",
    "            elif \"vision_tower\" in k:\n",
    "                new_k = \"thinker.model.\" + k\n",
    "            else:\n",
    "                new_k = k\n",
    "            tensors[new_k] = f.get_tensor(k)\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00001-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:08<01:30,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00002-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:15<00:29,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on modelo-00004-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:23<00:32,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00004-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:30<00:32,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on modelo-00005-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:33<00:23,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00005-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:39<00:06,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model-00003-of-00005.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:46<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import save_file\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "read_path = \"/data1/nowshad/models/gemma3_with_talker_base\"\n",
    "save_path = \"/data1/nowshad/models/gemma3_with_talker_base/mdf\"\n",
    "files = os.listdir(read_path)\n",
    "for file in tqdm(files):\n",
    "    if file.endswith(\"safetensors\"):\n",
    "        print(f\"Working on {file}\")\n",
    "        new_tensor = convert_tensor(os.path.join(read_path, file))\n",
    "        save_file(new_tensor, os.path.join(save_path, file))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"something\"\n",
    "\"some\" in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed token weights shape model.embed_tokens.weight is torch.Size([151936, 4096])\n",
      "LM head weights shape lm_head.weight is torch.Size([151936, 4096])\n"
     ]
    }
   ],
   "source": [
    "lm_head_file_path = (\n",
    "    \"/data1/nowshad/models/DeepSeek-R1-0528-Qwen3-8B/model-00002-of-000002.safetensors\"\n",
    ")\n",
    "embed_file_path = (\n",
    "    \"/data1/nowshad/models/DeepSeek-R1-0528-Qwen3-8B/model-00001-of-000002.safetensors\"\n",
    ")\n",
    "from safetensors import safe_open\n",
    "\n",
    "with safe_open(embed_file_path, framework=\"pt\", device=6) as f:\n",
    "    for k in f.keys():\n",
    "        if \"embed_tokens\" in k:\n",
    "            print(f\"Embed token weights shape {k} is {f.get_tensor(k).shape}\")\n",
    "\n",
    "with safe_open(lm_head_file_path, framework=\"pt\", device=6) as f:\n",
    "    for k in f.keys():\n",
    "        if \"lm_head\" in k:\n",
    "            print(f\"LM head weights shape {k} is {f.get_tensor(k).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something is 25-30 and country is SG and else is Playful'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"something is {age} and country is {country} and else is {style}\"\n",
    "x.format(age=\"25-30\", country=\"SG\", style=\"Playful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"thinker.model.language_model.embed_tokens.weight\": \"model-00001-of-00005.safetensors\"\n",
    "\n",
    "\"lm_head.weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed token weights shape thinker.model.language_model.embed_tokens.weight is torch.Size([262145, 3840])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "tensors = {}\n",
    "with safe_open(\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base/model-00001-of-00005.safetensors\",\n",
    "    framework=\"pt\",\n",
    "    device=6,\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        if \"embed_tokens\" in k:\n",
    "            print(f\"Embed token weights shape {k} is {f.get_tensor(k).shape}\")\n",
    "            tensors[\"thinker.model.lm_head.weight\"] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_open(\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base/model-00005-of-00005.safetensors\",\n",
    "    framework=\"pt\",\n",
    "    device=6,\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_file\n",
    "\n",
    "save_file(\n",
    "    tensors,\n",
    "    \"/data1/nowshad/models/gemma3_with_talker_base/model-00005-of-00005.safetensors\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
